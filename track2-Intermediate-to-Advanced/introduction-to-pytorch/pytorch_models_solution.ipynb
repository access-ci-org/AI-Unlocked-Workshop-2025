{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd628080-93ba-4633-9474-cd201c9ef48f",
   "metadata": {},
   "source": [
    "# PyTorch Model Notebook #\n",
    "This notebook will allow you to get practice in building and working with PyTorch models.  Code excersises denoted by a problem number (i.e. Problem #1) will include a task and a code block that asks for your solution.  These blocks will be denoted by comments of the form '# YOUR CODE HERE #'.  The code immediately following include assertions that are used to check completeness of the response.  They will raise an exception if the previous solution is not complete or not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934d40a-5dff-46f5-82ff-750df7005c96",
   "metadata": {},
   "source": [
    "## Datasets and DataLoaders\n",
    "\n",
    "Reference:  The Linux Foundation, \"Datasets & DataLoaders - PyTorch Tutorials 2.6.0 +cu124 documentation,\" pytorch.org https://pytorch.org/tutorials/beginner/basics/data_tutorial.html (accessed Mar. 20, 2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c02f8ea-d81e-4cbd-b2a0-9daa4a7d64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c696a-2822-429f-9029-d15ab78880ac",
   "metadata": {},
   "source": [
    "**Problem #1:**  Finish implementing the \"RandDataset\" Dataset by 1) setting \"self.mapping\" to a random tensor of dimension (output_dims, input_dims), 2) implementing the '\\_\\_len\\_\\_' method by returning the length of the dataset, and 3) setting the **output_tensor** = **Mx** in the '\\_\\_getitem\\_\\_' method, where **M** is the \"self.mapping\" tensor and **x** is the \"input_tensor\".  Also remember to implement the \"self.target_transform\" (if not None) on the \"output_tensor\", analagous to the \"self.transform\" already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12735c50-e079-45b1-90b9-bea833b31f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandDataset(Dataset):\n",
    "    def __init__(self, input_dims, output_dims, length, transform=None, target_transform=None):\n",
    "        self.input_dims = input_dims\n",
    "        self.output_dims = output_dims\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        ### BEGIN SOLUTION\n",
    "        self.mapping = torch.rand(output_dims, input_dims)  #Hint this is the random mapping tensor\n",
    "        ### END SOLUTION\n",
    "        self.length = length\n",
    "    ### BEGIN SOLUTION\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    ### END SOLUTION\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_tensor = torch.rand(self.input_dims)\n",
    "        if self.transform:\n",
    "            input_tensor = self.transform(input_tensor)\n",
    "        ### BEGIN SOLUTION\n",
    "        output_tensor = self.mapping.matmul(input_tensor)\n",
    "        if self.target_transform:\n",
    "            output_tensor = self.target_transform(output_tensor)\n",
    "        ### END SOLUTION\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "assert len(RandDataset(5,10,1000)) == 1000\n",
    "assert (RandDataset(5, 10, 1000)).mapping.shape == (10,5)\n",
    "assert (RandDataset(5, 10, 1000))[1][1].shape[0] == 10\n",
    "assert ((RandDataset(5, 10, 1000, target_transform=lambda x: x + 20))[1][1] > 20).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f8acf-a685-4611-a8d4-033dea5f3b2d",
   "metadata": {},
   "source": [
    "**Problem #2:**  Instatiate the RandDataset class with a length=32000 and variables \"input_dims\" and \"output_dims\".  Set variables named \"input_dims\" and \"output_dims\" to apropriate values and use in the RandDataset instantiation call. Also, instantiate a DataLoader using this dataset object using a \"batch_size\" of 32, already implemented. Name this dataloader object \"rand_dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61505be8-94d1-46d6-afab-1416d1221dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "### BEGIN SOLUTION\n",
    "input_dims, output_dims = 5, 10\n",
    "rand_dataset = RandDataset(input_dims, output_dims, 32000)\n",
    "rand_dataloader = DataLoader(rand_dataset, batch_size=batch_size)\n",
    "### END SOLUTION\n",
    "\n",
    "assert input_dims > 0 and output_dims > 0\n",
    "assert len(rand_dataloader.dataset) == 32000\n",
    "assert rand_dataloader.batch_size == 32\n",
    "assert len(rand_dataloader) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49cac2-7537-49fb-888f-f5c48a4f3570",
   "metadata": {},
   "source": [
    "**Setting the train and test dataloaders from above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b79a3f-9abd-4993-9a9d-e9002211447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "train_dataloader = rand_dataloader\n",
    "\n",
    "test_dataset = copy.deepcopy(train_dataloader.dataset)\n",
    "test_dataset.length = 1000\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "assert len(test_dataloader.dataset) == 1000\n",
    "assert (train_dataloader.dataset.mapping == test_dataloader.dataset.mapping).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d56cc-e67f-4103-b365-f565ec72595d",
   "metadata": {},
   "source": [
    "## Building the PyTorch Model ##\n",
    "\n",
    "Reference:  The Linux Foundation, \"Build the Neural Network - PyTorch Tutorials 2.6.0 +cu124 documentation,\" pytorch.org https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html (accessed Mar. 13, 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042e401-ef2a-477c-a319-ee5752d49260",
   "metadata": {},
   "source": [
    "**Problem #3:**  Implement a Pytorch model class named \"NNModel\". Fill in the instantiation of the model's layers, which should include a nn.Linear, nn.ReLU, nn.Linear, nn.ReLU, and nn.Linear layers.  There should be **n** input neurons, **h** hidden neurons, and **m** output neurons.  Hint: Both hidden linear layers (first two) should have **h** neurons. Implement the forward computation of the model using the **input_tensor** as input and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05988e93-2a2f-4adb-b15e-6698f8805871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self,n,m,h):\n",
    "        super().__init__()\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        self.stack = nn.Sequential(\n",
    "             nn.Linear(n,h),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(h,h),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(h, m),\n",
    "        )\n",
    "        ### END SOLUTION\n",
    "    \n",
    "    def forward(self, input_tensor):\n",
    "        ### BEGIN SOLUTION\n",
    "        y = self.stack(input_tensor)\n",
    "        return y\n",
    "        ### END SOLUTION\n",
    "\n",
    "import re\n",
    "assert ((NNModel(input_dims, output_dims, 50))(torch.rand(5,input_dims))).shape == (5,output_dims)\n",
    "assert len(re.findall('Linear', str(NNModel(input_dims, output_dims, 50)))) == 3\n",
    "assert len(re.findall('ReLU()', str(NNModel(input_dims, output_dims, 50)))) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e3e8c-bf0b-447f-8b38-964e83a07702",
   "metadata": {},
   "source": [
    "## Optimizing the PyTorch Model ##\n",
    "\n",
    "Reference:  The Linux Foundation, \"Optimizing Model Parameters - PyTorch Tutorials 2.6.0 +cu124 documentation,\" pytorch.org https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html (accessed Mar. 24, 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6fcb3-e8da-45d5-b425-bd90cbd90da5",
   "metadata": {},
   "source": [
    "**Problem #4:**  Instantiate the nn.MSELoss function with reduction='sum' and name the object, \"my_loss_fn\".  Instantiate the NNModel using \"input_dims\", \"output_dims\", and any number of hidden neurons and name the object, \"my_model\".   Instantiate the optim.SGD optimizer with the model parameters and the learning_rate defined above and name the object, \"my_optimizer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d741d4e-2fe3-4683-8383-7afe50861ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "learning_rate = 1e-2\n",
    "epochs = 50\n",
    "tolerance = 1e-2\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "my_loss_fn = nn.MSELoss(reduction='sum')\n",
    "my_model = NNModel(input_dims, output_dims, 20)\n",
    "my_optimizer = optim.SGD(my_model.parameters(), lr=learning_rate)\n",
    "### END SOLUTION\n",
    "\n",
    "assert isinstance(my_loss_fn, nn.MSELoss)\n",
    "assert my_loss_fn.reduction == 'sum'\n",
    "assert isinstance(my_model, NNModel)\n",
    "assert isinstance(my_optimizer, optim.SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc83551-bdc2-40a5-a5dd-e6cfc1ef1806",
   "metadata": {},
   "source": [
    "**Problem #5:**  Implement the training loop by including the 1) model predictions from the batch inputs, **X**, and calculating the loss via the loss_fn using the predictions and batch outputs, **Y**.  Divide the loss by the number of predictions to get the **avg_loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b5fc63-e026-4f6e-90b9-4ae7b4d76910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 4.258340, [current: 3200/ 3200]\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,Y) in enumerate(dataloader):\n",
    "        if device:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "        ### BEGIN SOLUTION\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, Y)\n",
    "        avg_loss = loss / len(pred)\n",
    "        ### END SOLUTION\n",
    "\n",
    "        avg_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (batch+1) %100 == 0:\n",
    "            avg_loss, current = avg_loss.item(), batch * batch_size + len(pred)\n",
    "            print(f\"Avg. loss: {avg_loss:>7f}, [current:{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return True\n",
    "\n",
    "assert train_loop(DataLoader(RandDataset(3,5,batch_size*100),batch_size=batch_size), NNModel(3,5,20), nn.MSELoss(reduction='sum'), optim.SGD((NNModel(3,5,20)).parameters(), lr=learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3ffcf-c6f3-46e1-9f9c-5313599c069c",
   "metadata": {},
   "source": [
    "**Problem #6:**  Implement the test loop by including the 1) model predictions from the batch inputs, **X**, and calculating the test loss via the loss_fn using the predictions and batch outputs, **Y**.  Divide the test_loss by the number of predictions and remember to use the .item() method to extract the scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7448f4-9984-4854-b2c3-c944bed76dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.0%, Avg. loss: 3.864772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_loop(dataloader, model, loss_fn, tolerance, device=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X,Y) in dataloader:\n",
    "            if device:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "            ### BEGIN SOLUTION\n",
    "            pred = model(X)\n",
    "            test_loss += (loss_fn(pred, Y) / len(pred)).item()\n",
    "            ### END SOLUTION\n",
    "            correct += ((pred - Y).abs() < tolerance).all(dim=1).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg. loss: {test_loss:>8f}\\n\")\n",
    "    return True\n",
    "\n",
    "assert test_loop(DataLoader(RandDataset(3,5,batch_size),batch_size=batch_size), NNModel(3,5,20), nn.MSELoss(reduction='sum'), tolerance=tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87940ae2-d8f9-4df3-a657-a4c4a2133317",
   "metadata": {},
   "source": [
    "**Implementing the epoch loop and running the training loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502ac28-f671-4fcb-9d48-ec983a5f1b70",
   "metadata": {},
   "source": [
    "**Problem #7:**  Implement the epoch loop by using the train_loop and test_loop functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d8bdc0-b401-47a0-8187-781a647c10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n",
      "Avg. loss: 0.466994, [current: 3200/32000]\n",
      "Avg. loss: 0.275905, [current: 6400/32000]\n",
      "Avg. loss: 0.173477, [current: 9600/32000]\n",
      "Avg. loss: 0.155771, [current:12800/32000]\n",
      "Avg. loss: 0.138271, [current:16000/32000]\n",
      "Avg. loss: 0.105612, [current:19200/32000]\n",
      "Avg. loss: 0.106437, [current:22400/32000]\n",
      "Avg. loss: 0.107267, [current:25600/32000]\n",
      "Avg. loss: 0.081672, [current:28800/32000]\n",
      "Avg. loss: 0.061309, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg. loss: 0.069360\n",
      "\n",
      "Epoch 2\n",
      "------------------------------\n",
      "Avg. loss: 0.052960, [current: 3200/32000]\n",
      "Avg. loss: 0.045673, [current: 6400/32000]\n",
      "Avg. loss: 0.034378, [current: 9600/32000]\n",
      "Avg. loss: 0.030830, [current:12800/32000]\n",
      "Avg. loss: 0.018746, [current:16000/32000]\n",
      "Avg. loss: 0.015056, [current:19200/32000]\n",
      "Avg. loss: 0.011399, [current:22400/32000]\n",
      "Avg. loss: 0.010450, [current:25600/32000]\n",
      "Avg. loss: 0.007051, [current:28800/32000]\n",
      "Avg. loss: 0.007651, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg. loss: 0.005618\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def epoch_loop(epochs, train_dataloader, test_dataloader, model, loss_fn, optimizer, tolerance, device=None):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n------------------------------\")\n",
    "        ### BEGIN SOLUTION ###\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(test_dataloader, model, loss_fn, tolerance, device)\n",
    "        ### END SOLUTION ###\n",
    "    print(\"Done\")\n",
    "    return True\n",
    "\n",
    "epochs_cpu = 2\n",
    "assert epoch_loop(epochs_cpu, train_dataloader, test_dataloader, my_model, my_loss_fn, my_optimizer, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad7c87-bd6a-434f-9a75-dbd011f61bc2",
   "metadata": {},
   "source": [
    "## Utilizing the GPU for Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58694019-31f5-47b2-ae3f-3c6d74056ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device - cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(torch.cuda.current_device())\n",
    "\n",
    "print(f\"Using device - {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127c0c2-64a2-4286-bdcc-0487b9233ccc",
   "metadata": {},
   "source": [
    "**Problem #8:**  If a GPU device is available, move \"my_model\" to the device and save as \"my_model_gpu\".  Reinitialize the SGD optimizer using \"my_model_gpu.parameters()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1dbab2c-a39b-42c6-9f25-5e184a556c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n",
      "Avg. loss: 0.004681, [current: 3200/32000]\n",
      "Avg. loss: 0.002996, [current: 6400/32000]\n",
      "Avg. loss: 0.003277, [current: 9600/32000]\n",
      "Avg. loss: 0.001482, [current:12800/32000]\n",
      "Avg. loss: 0.001766, [current:16000/32000]\n",
      "Avg. loss: 0.001653, [current:19200/32000]\n",
      "Avg. loss: 0.000958, [current:22400/32000]\n",
      "Avg. loss: 0.002503, [current:25600/32000]\n",
      "Avg. loss: 0.000641, [current:28800/32000]\n",
      "Avg. loss: 0.000622, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg. loss: 0.001426\n",
      "\n",
      "Epoch 2\n",
      "------------------------------\n",
      "Avg. loss: 0.001284, [current: 3200/32000]\n",
      "Avg. loss: 0.001154, [current: 6400/32000]\n",
      "Avg. loss: 0.001246, [current: 9600/32000]\n",
      "Avg. loss: 0.000883, [current:12800/32000]\n",
      "Avg. loss: 0.000802, [current:16000/32000]\n",
      "Avg. loss: 0.000592, [current:19200/32000]\n",
      "Avg. loss: 0.000378, [current:22400/32000]\n",
      "Avg. loss: 0.000213, [current:25600/32000]\n",
      "Avg. loss: 0.000165, [current:28800/32000]\n",
      "Avg. loss: 0.000207, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg. loss: 0.000410\n",
      "\n",
      "Epoch 3\n",
      "------------------------------\n",
      "Avg. loss: 0.000061, [current: 3200/32000]\n",
      "Avg. loss: 0.000440, [current: 6400/32000]\n",
      "Avg. loss: 0.001429, [current: 9600/32000]\n",
      "Avg. loss: 0.000525, [current:12800/32000]\n",
      "Avg. loss: 0.001630, [current:16000/32000]\n",
      "Avg. loss: 0.000237, [current:19200/32000]\n",
      "Avg. loss: 0.000529, [current:22400/32000]\n",
      "Avg. loss: 0.000137, [current:25600/32000]\n",
      "Avg. loss: 0.000900, [current:28800/32000]\n",
      "Avg. loss: 0.000709, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg. loss: 0.000313\n",
      "\n",
      "Epoch 4\n",
      "------------------------------\n",
      "Avg. loss: 0.000120, [current: 3200/32000]\n",
      "Avg. loss: 0.000384, [current: 6400/32000]\n",
      "Avg. loss: 0.000415, [current: 9600/32000]\n",
      "Avg. loss: 0.000222, [current:12800/32000]\n",
      "Avg. loss: 0.000769, [current:16000/32000]\n",
      "Avg. loss: 0.000100, [current:19200/32000]\n",
      "Avg. loss: 0.000102, [current:22400/32000]\n",
      "Avg. loss: 0.000282, [current:25600/32000]\n",
      "Avg. loss: 0.000081, [current:28800/32000]\n",
      "Avg. loss: 0.000813, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg. loss: 0.000299\n",
      "\n",
      "Epoch 5\n",
      "------------------------------\n",
      "Avg. loss: 0.000043, [current: 3200/32000]\n",
      "Avg. loss: 0.000546, [current: 6400/32000]\n",
      "Avg. loss: 0.000055, [current: 9600/32000]\n",
      "Avg. loss: 0.000019, [current:12800/32000]\n",
      "Avg. loss: 0.000171, [current:16000/32000]\n",
      "Avg. loss: 0.000797, [current:19200/32000]\n",
      "Avg. loss: 0.000291, [current:22400/32000]\n",
      "Avg. loss: 0.000553, [current:25600/32000]\n",
      "Avg. loss: 0.000078, [current:28800/32000]\n",
      "Avg. loss: 0.000557, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg. loss: 0.000359\n",
      "\n",
      "Epoch 6\n",
      "------------------------------\n",
      "Avg. loss: 0.000433, [current: 3200/32000]\n",
      "Avg. loss: 0.000076, [current: 6400/32000]\n",
      "Avg. loss: 0.000012, [current: 9600/32000]\n",
      "Avg. loss: 0.000438, [current:12800/32000]\n",
      "Avg. loss: 0.000049, [current:16000/32000]\n",
      "Avg. loss: 0.000052, [current:19200/32000]\n",
      "Avg. loss: 0.000014, [current:22400/32000]\n",
      "Avg. loss: 0.000221, [current:25600/32000]\n",
      "Avg. loss: 0.000218, [current:28800/32000]\n",
      "Avg. loss: 0.000054, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg. loss: 0.000195\n",
      "\n",
      "Epoch 7\n",
      "------------------------------\n",
      "Avg. loss: 0.000037, [current: 3200/32000]\n",
      "Avg. loss: 0.000066, [current: 6400/32000]\n",
      "Avg. loss: 0.000009, [current: 9600/32000]\n",
      "Avg. loss: 0.000102, [current:12800/32000]\n",
      "Avg. loss: 0.000370, [current:16000/32000]\n",
      "Avg. loss: 0.000098, [current:19200/32000]\n",
      "Avg. loss: 0.000080, [current:22400/32000]\n",
      "Avg. loss: 0.000241, [current:25600/32000]\n",
      "Avg. loss: 0.000181, [current:28800/32000]\n",
      "Avg. loss: 0.000103, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg. loss: 0.000248\n",
      "\n",
      "Epoch 8\n",
      "------------------------------\n",
      "Avg. loss: 0.000006, [current: 3200/32000]\n",
      "Avg. loss: 0.000244, [current: 6400/32000]\n",
      "Avg. loss: 0.000396, [current: 9600/32000]\n",
      "Avg. loss: 0.000219, [current:12800/32000]\n",
      "Avg. loss: 0.000019, [current:16000/32000]\n",
      "Avg. loss: 0.001043, [current:19200/32000]\n",
      "Avg. loss: 0.000520, [current:22400/32000]\n",
      "Avg. loss: 0.000077, [current:25600/32000]\n",
      "Avg. loss: 0.000381, [current:28800/32000]\n",
      "Avg. loss: 0.000129, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg. loss: 0.000154\n",
      "\n",
      "Epoch 9\n",
      "------------------------------\n",
      "Avg. loss: 0.000013, [current: 3200/32000]\n",
      "Avg. loss: 0.001963, [current: 6400/32000]\n",
      "Avg. loss: 0.000024, [current: 9600/32000]\n",
      "Avg. loss: 0.000028, [current:12800/32000]\n",
      "Avg. loss: 0.000081, [current:16000/32000]\n",
      "Avg. loss: 0.000048, [current:19200/32000]\n",
      "Avg. loss: 0.000036, [current:22400/32000]\n",
      "Avg. loss: 0.000061, [current:25600/32000]\n",
      "Avg. loss: 0.000077, [current:28800/32000]\n",
      "Avg. loss: 0.000005, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg. loss: 0.000167\n",
      "\n",
      "Epoch 10\n",
      "------------------------------\n",
      "Avg. loss: 0.000110, [current: 3200/32000]\n",
      "Avg. loss: 0.000228, [current: 6400/32000]\n",
      "Avg. loss: 0.000058, [current: 9600/32000]\n",
      "Avg. loss: 0.000270, [current:12800/32000]\n",
      "Avg. loss: 0.000033, [current:16000/32000]\n",
      "Avg. loss: 0.000069, [current:19200/32000]\n",
      "Avg. loss: 0.000025, [current:22400/32000]\n",
      "Avg. loss: 0.000121, [current:25600/32000]\n",
      "Avg. loss: 0.000276, [current:28800/32000]\n",
      "Avg. loss: 0.000127, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg. loss: 0.000110\n",
      "\n",
      "Epoch 11\n",
      "------------------------------\n",
      "Avg. loss: 0.000259, [current: 3200/32000]\n",
      "Avg. loss: 0.000020, [current: 6400/32000]\n",
      "Avg. loss: 0.000005, [current: 9600/32000]\n",
      "Avg. loss: 0.000018, [current:12800/32000]\n",
      "Avg. loss: 0.000049, [current:16000/32000]\n",
      "Avg. loss: 0.000024, [current:19200/32000]\n",
      "Avg. loss: 0.000082, [current:22400/32000]\n",
      "Avg. loss: 0.000004, [current:25600/32000]\n",
      "Avg. loss: 0.000195, [current:28800/32000]\n",
      "Avg. loss: 0.000026, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg. loss: 0.000113\n",
      "\n",
      "Epoch 12\n",
      "------------------------------\n",
      "Avg. loss: 0.000016, [current: 3200/32000]\n",
      "Avg. loss: 0.000401, [current: 6400/32000]\n",
      "Avg. loss: 0.000209, [current: 9600/32000]\n",
      "Avg. loss: 0.000060, [current:12800/32000]\n",
      "Avg. loss: 0.000194, [current:16000/32000]\n",
      "Avg. loss: 0.000346, [current:19200/32000]\n",
      "Avg. loss: 0.000012, [current:22400/32000]\n",
      "Avg. loss: 0.000008, [current:25600/32000]\n",
      "Avg. loss: 0.000110, [current:28800/32000]\n",
      "Avg. loss: 0.000080, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg. loss: 0.000118\n",
      "\n",
      "Epoch 13\n",
      "------------------------------\n",
      "Avg. loss: 0.000043, [current: 3200/32000]\n",
      "Avg. loss: 0.000009, [current: 6400/32000]\n",
      "Avg. loss: 0.000122, [current: 9600/32000]\n",
      "Avg. loss: 0.000377, [current:12800/32000]\n",
      "Avg. loss: 0.000020, [current:16000/32000]\n",
      "Avg. loss: 0.000087, [current:19200/32000]\n",
      "Avg. loss: 0.000038, [current:22400/32000]\n",
      "Avg. loss: 0.000003, [current:25600/32000]\n",
      "Avg. loss: 0.000025, [current:28800/32000]\n",
      "Avg. loss: 0.000007, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg. loss: 0.000104\n",
      "\n",
      "Epoch 14\n",
      "------------------------------\n",
      "Avg. loss: 0.000005, [current: 3200/32000]\n",
      "Avg. loss: 0.000046, [current: 6400/32000]\n",
      "Avg. loss: 0.000002, [current: 9600/32000]\n",
      "Avg. loss: 0.000072, [current:12800/32000]\n",
      "Avg. loss: 0.000010, [current:16000/32000]\n",
      "Avg. loss: 0.000024, [current:19200/32000]\n",
      "Avg. loss: 0.000008, [current:22400/32000]\n",
      "Avg. loss: 0.000003, [current:25600/32000]\n",
      "Avg. loss: 0.000134, [current:28800/32000]\n",
      "Avg. loss: 0.000019, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg. loss: 0.000128\n",
      "\n",
      "Epoch 15\n",
      "------------------------------\n",
      "Avg. loss: 0.000088, [current: 3200/32000]\n",
      "Avg. loss: 0.000009, [current: 6400/32000]\n",
      "Avg. loss: 0.000002, [current: 9600/32000]\n",
      "Avg. loss: 0.000002, [current:12800/32000]\n",
      "Avg. loss: 0.000004, [current:16000/32000]\n",
      "Avg. loss: 0.000003, [current:19200/32000]\n",
      "Avg. loss: 0.000002, [current:22400/32000]\n",
      "Avg. loss: 0.000348, [current:25600/32000]\n",
      "Avg. loss: 0.000108, [current:28800/32000]\n",
      "Avg. loss: 0.000010, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg. loss: 0.000100\n",
      "\n",
      "Epoch 16\n",
      "------------------------------\n",
      "Avg. loss: 0.000027, [current: 3200/32000]\n",
      "Avg. loss: 0.000015, [current: 6400/32000]\n",
      "Avg. loss: 0.000123, [current: 9600/32000]\n",
      "Avg. loss: 0.000012, [current:12800/32000]\n",
      "Avg. loss: 0.000088, [current:16000/32000]\n",
      "Avg. loss: 0.000002, [current:19200/32000]\n",
      "Avg. loss: 0.000013, [current:22400/32000]\n",
      "Avg. loss: 0.000003, [current:25600/32000]\n",
      "Avg. loss: 0.000155, [current:28800/32000]\n",
      "Avg. loss: 0.000224, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg. loss: 0.000058\n",
      "\n",
      "Epoch 17\n",
      "------------------------------\n",
      "Avg. loss: 0.000051, [current: 3200/32000]\n",
      "Avg. loss: 0.000056, [current: 6400/32000]\n",
      "Avg. loss: 0.000024, [current: 9600/32000]\n",
      "Avg. loss: 0.000003, [current:12800/32000]\n",
      "Avg. loss: 0.000042, [current:16000/32000]\n",
      "Avg. loss: 0.000003, [current:19200/32000]\n",
      "Avg. loss: 0.000015, [current:22400/32000]\n",
      "Avg. loss: 0.000200, [current:25600/32000]\n",
      "Avg. loss: 0.000020, [current:28800/32000]\n",
      "Avg. loss: 0.000026, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg. loss: 0.000038\n",
      "\n",
      "Epoch 18\n",
      "------------------------------\n",
      "Avg. loss: 0.000005, [current: 3200/32000]\n",
      "Avg. loss: 0.000002, [current: 6400/32000]\n",
      "Avg. loss: 0.000029, [current: 9600/32000]\n",
      "Avg. loss: 0.000612, [current:12800/32000]\n",
      "Avg. loss: 0.000002, [current:16000/32000]\n",
      "Avg. loss: 0.000032, [current:19200/32000]\n",
      "Avg. loss: 0.000006, [current:22400/32000]\n",
      "Avg. loss: 0.000002, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000011, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000088\n",
      "\n",
      "Epoch 19\n",
      "------------------------------\n",
      "Avg. loss: 0.000051, [current: 3200/32000]\n",
      "Avg. loss: 0.000028, [current: 6400/32000]\n",
      "Avg. loss: 0.000003, [current: 9600/32000]\n",
      "Avg. loss: 0.000180, [current:12800/32000]\n",
      "Avg. loss: 0.000002, [current:16000/32000]\n",
      "Avg. loss: 0.000002, [current:19200/32000]\n",
      "Avg. loss: 0.000021, [current:22400/32000]\n",
      "Avg. loss: 0.000001, [current:25600/32000]\n",
      "Avg. loss: 0.000005, [current:28800/32000]\n",
      "Avg. loss: 0.000029, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg. loss: 0.000027\n",
      "\n",
      "Epoch 20\n",
      "------------------------------\n",
      "Avg. loss: 0.000002, [current: 3200/32000]\n",
      "Avg. loss: 0.000090, [current: 6400/32000]\n",
      "Avg. loss: 0.000008, [current: 9600/32000]\n",
      "Avg. loss: 0.000049, [current:12800/32000]\n",
      "Avg. loss: 0.000003, [current:16000/32000]\n",
      "Avg. loss: 0.000004, [current:19200/32000]\n",
      "Avg. loss: 0.000006, [current:22400/32000]\n",
      "Avg. loss: 0.000011, [current:25600/32000]\n",
      "Avg. loss: 0.000015, [current:28800/32000]\n",
      "Avg. loss: 0.000005, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg. loss: 0.000045\n",
      "\n",
      "Epoch 21\n",
      "------------------------------\n",
      "Avg. loss: 0.000012, [current: 3200/32000]\n",
      "Avg. loss: 0.000170, [current: 6400/32000]\n",
      "Avg. loss: 0.000064, [current: 9600/32000]\n",
      "Avg. loss: 0.000009, [current:12800/32000]\n",
      "Avg. loss: 0.000063, [current:16000/32000]\n",
      "Avg. loss: 0.000024, [current:19200/32000]\n",
      "Avg. loss: 0.000021, [current:22400/32000]\n",
      "Avg. loss: 0.000077, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000012, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg. loss: 0.000087\n",
      "\n",
      "Epoch 22\n",
      "------------------------------\n",
      "Avg. loss: 0.000050, [current: 3200/32000]\n",
      "Avg. loss: 0.000028, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000001, [current:12800/32000]\n",
      "Avg. loss: 0.000003, [current:16000/32000]\n",
      "Avg. loss: 0.000001, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000001, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000016, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg. loss: 0.000109\n",
      "\n",
      "Epoch 23\n",
      "------------------------------\n",
      "Avg. loss: 0.000219, [current: 3200/32000]\n",
      "Avg. loss: 0.000231, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000206, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000001, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000035, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000002, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg. loss: 0.000065\n",
      "\n",
      "Epoch 24\n",
      "------------------------------\n",
      "Avg. loss: 0.000010, [current: 3200/32000]\n",
      "Avg. loss: 0.000007, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000006, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000010, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000006, [current:25600/32000]\n",
      "Avg. loss: 0.000161, [current:28800/32000]\n",
      "Avg. loss: 0.000009, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000026\n",
      "\n",
      "Epoch 25\n",
      "------------------------------\n",
      "Avg. loss: 0.000002, [current: 3200/32000]\n",
      "Avg. loss: 0.000045, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000002, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000771, [current:19200/32000]\n",
      "Avg. loss: 0.000002, [current:22400/32000]\n",
      "Avg. loss: 0.000045, [current:25600/32000]\n",
      "Avg. loss: 0.000008, [current:28800/32000]\n",
      "Avg. loss: 0.000021, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg. loss: 0.000024\n",
      "\n",
      "Epoch 26\n",
      "------------------------------\n",
      "Avg. loss: 0.000004, [current: 3200/32000]\n",
      "Avg. loss: 0.000001, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000003, [current:12800/32000]\n",
      "Avg. loss: 0.000008, [current:16000/32000]\n",
      "Avg. loss: 0.000088, [current:19200/32000]\n",
      "Avg. loss: 0.000051, [current:22400/32000]\n",
      "Avg. loss: 0.000018, [current:25600/32000]\n",
      "Avg. loss: 0.000032, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000017\n",
      "\n",
      "Epoch 27\n",
      "------------------------------\n",
      "Avg. loss: 0.000001, [current: 3200/32000]\n",
      "Avg. loss: 0.000004, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000979, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000005, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000001, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg. loss: 0.000033\n",
      "\n",
      "Epoch 28\n",
      "------------------------------\n",
      "Avg. loss: 0.000020, [current: 3200/32000]\n",
      "Avg. loss: 0.000004, [current: 6400/32000]\n",
      "Avg. loss: 0.000052, [current: 9600/32000]\n",
      "Avg. loss: 0.000018, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000002, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000035, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000102, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg. loss: 0.000026\n",
      "\n",
      "Epoch 29\n",
      "------------------------------\n",
      "Avg. loss: 0.000001, [current: 3200/32000]\n",
      "Avg. loss: 0.000009, [current: 6400/32000]\n",
      "Avg. loss: 0.000020, [current: 9600/32000]\n",
      "Avg. loss: 0.000003, [current:12800/32000]\n",
      "Avg. loss: 0.000003, [current:16000/32000]\n",
      "Avg. loss: 0.000099, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000027, [current:25600/32000]\n",
      "Avg. loss: 0.000012, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg. loss: 0.000049\n",
      "\n",
      "Epoch 30\n",
      "------------------------------\n",
      "Avg. loss: 0.000011, [current: 3200/32000]\n",
      "Avg. loss: 0.000008, [current: 6400/32000]\n",
      "Avg. loss: 0.000015, [current: 9600/32000]\n",
      "Avg. loss: 0.000001, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000014, [current:19200/32000]\n",
      "Avg. loss: 0.000046, [current:22400/32000]\n",
      "Avg. loss: 0.000014, [current:25600/32000]\n",
      "Avg. loss: 0.000289, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg. loss: 0.000059\n",
      "\n",
      "Epoch 31\n",
      "------------------------------\n",
      "Avg. loss: 0.000019, [current: 3200/32000]\n",
      "Avg. loss: 0.000012, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000337, [current:12800/32000]\n",
      "Avg. loss: 0.000018, [current:16000/32000]\n",
      "Avg. loss: 0.000001, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000001, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000017, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg. loss: 0.000024\n",
      "\n",
      "Epoch 32\n",
      "------------------------------\n",
      "Avg. loss: 0.000006, [current: 3200/32000]\n",
      "Avg. loss: 0.000004, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000010, [current:12800/32000]\n",
      "Avg. loss: 0.000083, [current:16000/32000]\n",
      "Avg. loss: 0.000106, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000003, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg. loss: 0.000015\n",
      "\n",
      "Epoch 33\n",
      "------------------------------\n",
      "Avg. loss: 0.000001, [current: 3200/32000]\n",
      "Avg. loss: 0.000085, [current: 6400/32000]\n",
      "Avg. loss: 0.000003, [current: 9600/32000]\n",
      "Avg. loss: 0.000034, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000001, [current:19200/32000]\n",
      "Avg. loss: 0.000007, [current:22400/32000]\n",
      "Avg. loss: 0.000008, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg. loss: 0.000047\n",
      "\n",
      "Epoch 34\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000003, [current: 6400/32000]\n",
      "Avg. loss: 0.000007, [current: 9600/32000]\n",
      "Avg. loss: 0.000015, [current:12800/32000]\n",
      "Avg. loss: 0.000022, [current:16000/32000]\n",
      "Avg. loss: 0.000017, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000016, [current:25600/32000]\n",
      "Avg. loss: 0.000001, [current:28800/32000]\n",
      "Avg. loss: 0.000002, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg. loss: 0.000018\n",
      "\n",
      "Epoch 35\n",
      "------------------------------\n",
      "Avg. loss: 0.000004, [current: 3200/32000]\n",
      "Avg. loss: 0.000007, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000001, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000003, [current:25600/32000]\n",
      "Avg. loss: 0.000015, [current:28800/32000]\n",
      "Avg. loss: 0.000003, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg. loss: 0.000148\n",
      "\n",
      "Epoch 36\n",
      "------------------------------\n",
      "Avg. loss: 0.000007, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000000, [current:12800/32000]\n",
      "Avg. loss: 0.000007, [current:16000/32000]\n",
      "Avg. loss: 0.000003, [current:19200/32000]\n",
      "Avg. loss: 0.000002, [current:22400/32000]\n",
      "Avg. loss: 0.000001, [current:25600/32000]\n",
      "Avg. loss: 0.000007, [current:28800/32000]\n",
      "Avg. loss: 0.000032, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg. loss: 0.000010\n",
      "\n",
      "Epoch 37\n",
      "------------------------------\n",
      "Avg. loss: 0.000014, [current: 3200/32000]\n",
      "Avg. loss: 0.000023, [current: 6400/32000]\n",
      "Avg. loss: 0.000003, [current: 9600/32000]\n",
      "Avg. loss: 0.000030, [current:12800/32000]\n",
      "Avg. loss: 0.000019, [current:16000/32000]\n",
      "Avg. loss: 0.000002, [current:19200/32000]\n",
      "Avg. loss: 0.000007, [current:22400/32000]\n",
      "Avg. loss: 0.000054, [current:25600/32000]\n",
      "Avg. loss: 0.000008, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000065\n",
      "\n",
      "Epoch 38\n",
      "------------------------------\n",
      "Avg. loss: 0.000004, [current: 3200/32000]\n",
      "Avg. loss: 0.000006, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000055, [current:12800/32000]\n",
      "Avg. loss: 0.000014, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000001, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000020, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000018\n",
      "\n",
      "Epoch 39\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000001, [current:12800/32000]\n",
      "Avg. loss: 0.000003, [current:16000/32000]\n",
      "Avg. loss: 0.000006, [current:19200/32000]\n",
      "Avg. loss: 0.000003, [current:22400/32000]\n",
      "Avg. loss: 0.000045, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000124, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg. loss: 0.000059\n",
      "\n",
      "Epoch 40\n",
      "------------------------------\n",
      "Avg. loss: 0.000026, [current: 3200/32000]\n",
      "Avg. loss: 0.000001, [current: 6400/32000]\n",
      "Avg. loss: 0.000047, [current: 9600/32000]\n",
      "Avg. loss: 0.000025, [current:12800/32000]\n",
      "Avg. loss: 0.000045, [current:16000/32000]\n",
      "Avg. loss: 0.000089, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000002, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg. loss: 0.000033\n",
      "\n",
      "Epoch 41\n",
      "------------------------------\n",
      "Avg. loss: 0.000003, [current: 3200/32000]\n",
      "Avg. loss: 0.000069, [current: 6400/32000]\n",
      "Avg. loss: 0.000299, [current: 9600/32000]\n",
      "Avg. loss: 0.000000, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000032, [current:19200/32000]\n",
      "Avg. loss: 0.000002, [current:22400/32000]\n",
      "Avg. loss: 0.000141, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000000, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000013\n",
      "\n",
      "Epoch 42\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000001, [current: 6400/32000]\n",
      "Avg. loss: 0.000001, [current: 9600/32000]\n",
      "Avg. loss: 0.000010, [current:12800/32000]\n",
      "Avg. loss: 0.000002, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000012, [current:22400/32000]\n",
      "Avg. loss: 0.000017, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000000, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg. loss: 0.000005\n",
      "\n",
      "Epoch 43\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000008, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000001, [current:19200/32000]\n",
      "Avg. loss: 0.000011, [current:22400/32000]\n",
      "Avg. loss: 0.000024, [current:25600/32000]\n",
      "Avg. loss: 0.000075, [current:28800/32000]\n",
      "Avg. loss: 0.000001, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg. loss: 0.000024\n",
      "\n",
      "Epoch 44\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000005, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000012, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000041, [current:19200/32000]\n",
      "Avg. loss: 0.000027, [current:22400/32000]\n",
      "Avg. loss: 0.000018, [current:25600/32000]\n",
      "Avg. loss: 0.000007, [current:28800/32000]\n",
      "Avg. loss: 0.000002, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg. loss: 0.000007\n",
      "\n",
      "Epoch 45\n",
      "------------------------------\n",
      "Avg. loss: 0.000020, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000000, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000099, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000014, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg. loss: 0.000017\n",
      "\n",
      "Epoch 46\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000000, [current: 9600/32000]\n",
      "Avg. loss: 0.000000, [current:12800/32000]\n",
      "Avg. loss: 0.000032, [current:16000/32000]\n",
      "Avg. loss: 0.000036, [current:19200/32000]\n",
      "Avg. loss: 0.000182, [current:22400/32000]\n",
      "Avg. loss: 0.000007, [current:25600/32000]\n",
      "Avg. loss: 0.000000, [current:28800/32000]\n",
      "Avg. loss: 0.000000, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000015\n",
      "\n",
      "Epoch 47\n",
      "------------------------------\n",
      "Avg. loss: 0.000051, [current: 3200/32000]\n",
      "Avg. loss: 0.000023, [current: 6400/32000]\n",
      "Avg. loss: 0.000003, [current: 9600/32000]\n",
      "Avg. loss: 0.000007, [current:12800/32000]\n",
      "Avg. loss: 0.000006, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000003, [current:28800/32000]\n",
      "Avg. loss: 0.000013, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000014\n",
      "\n",
      "Epoch 48\n",
      "------------------------------\n",
      "Avg. loss: 0.000074, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000205, [current: 9600/32000]\n",
      "Avg. loss: 0.000000, [current:12800/32000]\n",
      "Avg. loss: 0.000000, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000002, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg. loss: 0.000015\n",
      "\n",
      "Epoch 49\n",
      "------------------------------\n",
      "Avg. loss: 0.000005, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000002, [current: 9600/32000]\n",
      "Avg. loss: 0.000009, [current:12800/32000]\n",
      "Avg. loss: 0.000001, [current:16000/32000]\n",
      "Avg. loss: 0.000029, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000002, [current:25600/32000]\n",
      "Avg. loss: 0.000002, [current:28800/32000]\n",
      "Avg. loss: 0.000000, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg. loss: 0.000014\n",
      "\n",
      "Epoch 50\n",
      "------------------------------\n",
      "Avg. loss: 0.000000, [current: 3200/32000]\n",
      "Avg. loss: 0.000000, [current: 6400/32000]\n",
      "Avg. loss: 0.000040, [current: 9600/32000]\n",
      "Avg. loss: 0.000023, [current:12800/32000]\n",
      "Avg. loss: 0.000026, [current:16000/32000]\n",
      "Avg. loss: 0.000000, [current:19200/32000]\n",
      "Avg. loss: 0.000000, [current:22400/32000]\n",
      "Avg. loss: 0.000000, [current:25600/32000]\n",
      "Avg. loss: 0.000083, [current:28800/32000]\n",
      "Avg. loss: 0.000000, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000055\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ### BEGIN SOUTION\n",
    "    my_model_gpu = my_model.to(device)\n",
    "    my_optimizer_gpu = optim.SGD(my_model_gpu.parameters(), lr=learning_rate)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    assert epoch_loop(epochs, train_dataloader, test_dataloader, my_model_gpu, my_loss_fn, my_optimizer_gpu, tolerance, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5c29a-ea07-4e0e-b0be-0b55752e491f",
   "metadata": {},
   "source": [
    "## Saving and Loading PyTorch Models ##\n",
    "\n",
    "Reference:  The Linux Foundation, \"Save and Load the Model - PyTorch Tutorials 2.6.0 +cu124 documentation,\" pytorch.org https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html (accessed Mar. 24, 2025).\n",
    "\n",
    "Reference:  The Linux Foundation, \"Saving and Loading Models - PyTorch Tutorials 2.6.0 +cu124 documentation,\" pytorch.org https://pytorch.org/tutorials/beginner/saving_loading_models.html (accessed Mar. 24, 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50f2a9-eddd-482f-80a2-d46183501492",
   "metadata": {},
   "source": [
    "**Problem #9:**  Finish the implementation of the save_model_checkpoint funciton. Add the elements to the save_dict dictionary corresponding to keys, \"model_state_dict\", \"optimizer_state_dict\", and \"epoch\".  The values for these should be the .state_dict() for the model and optimizer and the epoch. Secondly, add the function to save the save_dict as a file given in file_path. Hint:  Use torch.save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c259de-7f33-422c-b61f-1cab2fed3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, optimizer, dataloader, epoch, file_path):\n",
    "    dataloader_mapping = dataloader.dataset.mapping\n",
    "    save_dict = dict(\n",
    "        ### BEGIN SOLUTION ###\n",
    "        model_state_dict = model.state_dict(), \n",
    "        optimizer_state_dict = optimizer.state_dict(), \n",
    "        epoch = epoch, \n",
    "        ### END SOLUTION ###\n",
    "        dataloader_mapping = dataloader_mapping,\n",
    "    )\n",
    "    ### BEGIN SOLUTION ###\n",
    "    torch.save(save_dict,file_path)\n",
    "    ### END SOLUTION ###\n",
    "    return True\n",
    "\n",
    "from pathlib import Path\n",
    "assert save_model_checkpoint(NNModel(3,5,20), optim.SGD((NNModel(3,5,20)).parameters(), lr=learning_rate), DataLoader(RandDataset(3,5,batch_size),batch_size=batch_size), 20, Path() / \"test_checkpoint.pth\")\n",
    "assert not set(['model_state_dict','optimizer_state_dict','epoch','dataloader_mapping']) - set((torch.load(Path() / \"test_checkpoint.pth\", weights_only=True)).keys())\n",
    "for key, val in (torch.load(Path() / \"test_checkpoint.pth\", weights_only=True)).items():\n",
    "    if 'dict' in key:\n",
    "        assert isinstance(val, dict)\n",
    "    elif key == 'epoch':\n",
    "        assert val == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f0bc1-ada0-486e-ac51-00296faee9b7",
   "metadata": {},
   "source": [
    "**Problem #9:**  Finish the implementation of the \"restore_model_checkpoint\" function. Load the checkpoint file defined at \"file_path\" using torch.load(...).  Update the \"model\" and \"optimizer\" state_dicts from the checkpoint.  Update the \"epoch\" variable from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790b821b-334d-45df-9ff8-860974a93962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting from checkpoint: test_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "def restore_model_checkpoint(model, optimizer, train_dataloader, test_dataloader, file_path):\n",
    "    epoch = -1\n",
    "    if file_path.exists():\n",
    "        print(f\"Restarting from checkpoint: {str(file_path)}\")\n",
    "        ### BEGIN SOLUTION ###\n",
    "        checkpoint = torch.load(file_path, weights_only=True)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        ### END SOLUTION\n",
    "        train_dataloader.dataset.mapping = checkpoint['dataloader_mapping']\n",
    "        test_dataloader.dataset.mapping = checkpoint['dataloader_mapping']\n",
    "    return epoch\n",
    "\n",
    "test_model = NNModel(3,5,20)\n",
    "test_optim = optim.SGD(test_model.parameters(), lr=learning_rate)\n",
    "assert restore_model_checkpoint(test_model,test_optim,DataLoader(RandDataset(3,5,batch_size),batch_size=batch_size),DataLoader(RandDataset(3,5,batch_size),batch_size=batch_size),Path() / \"test_checkpoint.pth\") == 20\n",
    "(Path() / \"test_checkpoint.pth\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0bc3c-3c57-4151-8aad-9c7d11de06c2",
   "metadata": {},
   "source": [
    "**Problem #10:**  Reimplement the \"epoch_loop\" with the restore_model_checkpoint and save_model_checkpoint functions. The epoch returned by restore_model_checkpoint should be saved to the \"epoch_last\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73acc0f1-413d-4d9f-a2a3-abf257b5e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n",
      "Avg. loss: 0.688889, [current: 3200/32000]\n",
      "Avg. loss: 0.300688, [current: 6400/32000]\n",
      "Avg. loss: 0.207974, [current: 9600/32000]\n",
      "Avg. loss: 0.161903, [current:12800/32000]\n",
      "Avg. loss: 0.165507, [current:16000/32000]\n",
      "Avg. loss: 0.160524, [current:19200/32000]\n",
      "Avg. loss: 0.169589, [current:22400/32000]\n",
      "Avg. loss: 0.153118, [current:25600/32000]\n",
      "Avg. loss: 0.108491, [current:28800/32000]\n",
      "Avg. loss: 0.100971, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg. loss: 0.111498\n",
      "\n",
      "Epoch 2\n",
      "------------------------------\n",
      "Avg. loss: 0.103993, [current: 3200/32000]\n",
      "Avg. loss: 0.093950, [current: 6400/32000]\n",
      "Avg. loss: 0.069131, [current: 9600/32000]\n",
      "Avg. loss: 0.050902, [current:12800/32000]\n",
      "Avg. loss: 0.056272, [current:16000/32000]\n",
      "Avg. loss: 0.042546, [current:19200/32000]\n",
      "Avg. loss: 0.035998, [current:22400/32000]\n",
      "Avg. loss: 0.028343, [current:25600/32000]\n",
      "Avg. loss: 0.022143, [current:28800/32000]\n",
      "Avg. loss: 0.023384, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg. loss: 0.017768\n",
      "\n",
      "Epoch 3\n",
      "------------------------------\n",
      "Avg. loss: 0.016162, [current: 3200/32000]\n",
      "Avg. loss: 0.010472, [current: 6400/32000]\n",
      "Avg. loss: 0.007944, [current: 9600/32000]\n",
      "Avg. loss: 0.006801, [current:12800/32000]\n",
      "Avg. loss: 0.004342, [current:16000/32000]\n",
      "Avg. loss: 0.003429, [current:19200/32000]\n",
      "Avg. loss: 0.002728, [current:22400/32000]\n",
      "Avg. loss: 0.002350, [current:25600/32000]\n",
      "Avg. loss: 0.002087, [current:28800/32000]\n",
      "Avg. loss: 0.001348, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 7.0%, Avg. loss: 0.002230\n",
      "\n",
      "Done\n",
      "Restarting from checkpoint: my_checkpoint_file.pth\n",
      "Epoch 4\n",
      "------------------------------\n",
      "Avg. loss: 0.001103, [current: 3200/32000]\n",
      "Avg. loss: 0.000698, [current: 6400/32000]\n",
      "Avg. loss: 0.001993, [current: 9600/32000]\n",
      "Avg. loss: 0.001170, [current:12800/32000]\n",
      "Avg. loss: 0.001497, [current:16000/32000]\n",
      "Avg. loss: 0.001427, [current:19200/32000]\n",
      "Avg. loss: 0.001197, [current:22400/32000]\n",
      "Avg. loss: 0.001315, [current:25600/32000]\n",
      "Avg. loss: 0.000369, [current:28800/32000]\n",
      "Avg. loss: 0.001260, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg. loss: 0.000775\n",
      "\n",
      "Epoch 5\n",
      "------------------------------\n",
      "Avg. loss: 0.000614, [current: 3200/32000]\n",
      "Avg. loss: 0.000647, [current: 6400/32000]\n",
      "Avg. loss: 0.000366, [current: 9600/32000]\n",
      "Avg. loss: 0.000267, [current:12800/32000]\n",
      "Avg. loss: 0.001092, [current:16000/32000]\n",
      "Avg. loss: 0.001104, [current:19200/32000]\n",
      "Avg. loss: 0.000758, [current:22400/32000]\n",
      "Avg. loss: 0.000551, [current:25600/32000]\n",
      "Avg. loss: 0.000522, [current:28800/32000]\n",
      "Avg. loss: 0.000787, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg. loss: 0.000695\n",
      "\n",
      "Epoch 6\n",
      "------------------------------\n",
      "Avg. loss: 0.001064, [current: 3200/32000]\n",
      "Avg. loss: 0.000580, [current: 6400/32000]\n",
      "Avg. loss: 0.000513, [current: 9600/32000]\n",
      "Avg. loss: 0.000629, [current:12800/32000]\n",
      "Avg. loss: 0.000368, [current:16000/32000]\n",
      "Avg. loss: 0.000305, [current:19200/32000]\n",
      "Avg. loss: 0.000490, [current:22400/32000]\n",
      "Avg. loss: 0.000828, [current:25600/32000]\n",
      "Avg. loss: 0.000267, [current:28800/32000]\n",
      "Avg. loss: 0.000248, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg. loss: 0.000614\n",
      "\n",
      "Epoch 7\n",
      "------------------------------\n",
      "Avg. loss: 0.000453, [current: 3200/32000]\n",
      "Avg. loss: 0.000231, [current: 6400/32000]\n",
      "Avg. loss: 0.000764, [current: 9600/32000]\n",
      "Avg. loss: 0.000282, [current:12800/32000]\n",
      "Avg. loss: 0.000759, [current:16000/32000]\n",
      "Avg. loss: 0.000249, [current:19200/32000]\n",
      "Avg. loss: 0.000639, [current:22400/32000]\n",
      "Avg. loss: 0.000373, [current:25600/32000]\n",
      "Avg. loss: 0.001084, [current:28800/32000]\n",
      "Avg. loss: 0.000612, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg. loss: 0.000571\n",
      "\n",
      "Epoch 8\n",
      "------------------------------\n",
      "Avg. loss: 0.000411, [current: 3200/32000]\n",
      "Avg. loss: 0.000386, [current: 6400/32000]\n",
      "Avg. loss: 0.000562, [current: 9600/32000]\n",
      "Avg. loss: 0.001299, [current:12800/32000]\n",
      "Avg. loss: 0.001211, [current:16000/32000]\n",
      "Avg. loss: 0.000445, [current:19200/32000]\n",
      "Avg. loss: 0.000417, [current:22400/32000]\n",
      "Avg. loss: 0.000440, [current:25600/32000]\n",
      "Avg. loss: 0.000215, [current:28800/32000]\n",
      "Avg. loss: 0.000498, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg. loss: 0.000352\n",
      "\n",
      "Epoch 9\n",
      "------------------------------\n",
      "Avg. loss: 0.000425, [current: 3200/32000]\n",
      "Avg. loss: 0.000368, [current: 6400/32000]\n",
      "Avg. loss: 0.000341, [current: 9600/32000]\n",
      "Avg. loss: 0.000341, [current:12800/32000]\n",
      "Avg. loss: 0.000418, [current:16000/32000]\n",
      "Avg. loss: 0.000193, [current:19200/32000]\n",
      "Avg. loss: 0.000600, [current:22400/32000]\n",
      "Avg. loss: 0.000365, [current:25600/32000]\n",
      "Avg. loss: 0.000354, [current:28800/32000]\n",
      "Avg. loss: 0.000223, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg. loss: 0.000296\n",
      "\n",
      "Epoch 10\n",
      "------------------------------\n",
      "Avg. loss: 0.000286, [current: 3200/32000]\n",
      "Avg. loss: 0.000290, [current: 6400/32000]\n",
      "Avg. loss: 0.000442, [current: 9600/32000]\n",
      "Avg. loss: 0.000131, [current:12800/32000]\n",
      "Avg. loss: 0.000512, [current:16000/32000]\n",
      "Avg. loss: 0.000396, [current:19200/32000]\n",
      "Avg. loss: 0.000604, [current:22400/32000]\n",
      "Avg. loss: 0.000377, [current:25600/32000]\n",
      "Avg. loss: 0.000351, [current:28800/32000]\n",
      "Avg. loss: 0.000199, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg. loss: 0.000327\n",
      "\n",
      "Epoch 11\n",
      "------------------------------\n",
      "Avg. loss: 0.000262, [current: 3200/32000]\n",
      "Avg. loss: 0.000345, [current: 6400/32000]\n",
      "Avg. loss: 0.000134, [current: 9600/32000]\n",
      "Avg. loss: 0.000246, [current:12800/32000]\n",
      "Avg. loss: 0.000667, [current:16000/32000]\n",
      "Avg. loss: 0.000101, [current:19200/32000]\n",
      "Avg. loss: 0.000759, [current:22400/32000]\n",
      "Avg. loss: 0.000409, [current:25600/32000]\n",
      "Avg. loss: 0.000193, [current:28800/32000]\n",
      "Avg. loss: 0.000315, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg. loss: 0.000249\n",
      "\n",
      "Epoch 12\n",
      "------------------------------\n",
      "Avg. loss: 0.000098, [current: 3200/32000]\n",
      "Avg. loss: 0.000411, [current: 6400/32000]\n",
      "Avg. loss: 0.000194, [current: 9600/32000]\n",
      "Avg. loss: 0.000175, [current:12800/32000]\n",
      "Avg. loss: 0.000206, [current:16000/32000]\n",
      "Avg. loss: 0.000085, [current:19200/32000]\n",
      "Avg. loss: 0.000438, [current:22400/32000]\n",
      "Avg. loss: 0.000202, [current:25600/32000]\n",
      "Avg. loss: 0.000264, [current:28800/32000]\n",
      "Avg. loss: 0.000139, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg. loss: 0.000415\n",
      "\n",
      "Epoch 13\n",
      "------------------------------\n",
      "Avg. loss: 0.000274, [current: 3200/32000]\n",
      "Avg. loss: 0.000151, [current: 6400/32000]\n",
      "Avg. loss: 0.000145, [current: 9600/32000]\n",
      "Avg. loss: 0.000250, [current:12800/32000]\n",
      "Avg. loss: 0.000179, [current:16000/32000]\n",
      "Avg. loss: 0.000321, [current:19200/32000]\n",
      "Avg. loss: 0.000519, [current:22400/32000]\n",
      "Avg. loss: 0.000214, [current:25600/32000]\n",
      "Avg. loss: 0.000126, [current:28800/32000]\n",
      "Avg. loss: 0.000238, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg. loss: 0.000265\n",
      "\n",
      "Epoch 14\n",
      "------------------------------\n",
      "Avg. loss: 0.000262, [current: 3200/32000]\n",
      "Avg. loss: 0.000360, [current: 6400/32000]\n",
      "Avg. loss: 0.000122, [current: 9600/32000]\n",
      "Avg. loss: 0.000190, [current:12800/32000]\n",
      "Avg. loss: 0.000102, [current:16000/32000]\n",
      "Avg. loss: 0.000173, [current:19200/32000]\n",
      "Avg. loss: 0.000123, [current:22400/32000]\n",
      "Avg. loss: 0.000346, [current:25600/32000]\n",
      "Avg. loss: 0.000213, [current:28800/32000]\n",
      "Avg. loss: 0.000107, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg. loss: 0.000146\n",
      "\n",
      "Epoch 15\n",
      "------------------------------\n",
      "Avg. loss: 0.000117, [current: 3200/32000]\n",
      "Avg. loss: 0.000110, [current: 6400/32000]\n",
      "Avg. loss: 0.000413, [current: 9600/32000]\n",
      "Avg. loss: 0.000077, [current:12800/32000]\n",
      "Avg. loss: 0.000173, [current:16000/32000]\n",
      "Avg. loss: 0.000214, [current:19200/32000]\n",
      "Avg. loss: 0.000116, [current:22400/32000]\n",
      "Avg. loss: 0.000146, [current:25600/32000]\n",
      "Avg. loss: 0.000072, [current:28800/32000]\n",
      "Avg. loss: 0.000098, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg. loss: 0.000190\n",
      "\n",
      "Epoch 16\n",
      "------------------------------\n",
      "Avg. loss: 0.000152, [current: 3200/32000]\n",
      "Avg. loss: 0.000082, [current: 6400/32000]\n",
      "Avg. loss: 0.000068, [current: 9600/32000]\n",
      "Avg. loss: 0.000213, [current:12800/32000]\n",
      "Avg. loss: 0.000144, [current:16000/32000]\n",
      "Avg. loss: 0.000145, [current:19200/32000]\n",
      "Avg. loss: 0.000093, [current:22400/32000]\n",
      "Avg. loss: 0.000115, [current:25600/32000]\n",
      "Avg. loss: 0.000148, [current:28800/32000]\n",
      "Avg. loss: 0.000108, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg. loss: 0.000186\n",
      "\n",
      "Epoch 17\n",
      "------------------------------\n",
      "Avg. loss: 0.000113, [current: 3200/32000]\n",
      "Avg. loss: 0.000217, [current: 6400/32000]\n",
      "Avg. loss: 0.000107, [current: 9600/32000]\n",
      "Avg. loss: 0.000087, [current:12800/32000]\n",
      "Avg. loss: 0.000161, [current:16000/32000]\n",
      "Avg. loss: 0.000078, [current:19200/32000]\n",
      "Avg. loss: 0.000047, [current:22400/32000]\n",
      "Avg. loss: 0.000108, [current:25600/32000]\n",
      "Avg. loss: 0.000062, [current:28800/32000]\n",
      "Avg. loss: 0.000084, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg. loss: 0.000122\n",
      "\n",
      "Epoch 18\n",
      "------------------------------\n",
      "Avg. loss: 0.000146, [current: 3200/32000]\n",
      "Avg. loss: 0.000246, [current: 6400/32000]\n",
      "Avg. loss: 0.000100, [current: 9600/32000]\n",
      "Avg. loss: 0.000070, [current:12800/32000]\n",
      "Avg. loss: 0.000128, [current:16000/32000]\n",
      "Avg. loss: 0.000151, [current:19200/32000]\n",
      "Avg. loss: 0.000059, [current:22400/32000]\n",
      "Avg. loss: 0.000121, [current:25600/32000]\n",
      "Avg. loss: 0.000465, [current:28800/32000]\n",
      "Avg. loss: 0.000081, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg. loss: 0.000134\n",
      "\n",
      "Epoch 19\n",
      "------------------------------\n",
      "Avg. loss: 0.000072, [current: 3200/32000]\n",
      "Avg. loss: 0.000046, [current: 6400/32000]\n",
      "Avg. loss: 0.000076, [current: 9600/32000]\n",
      "Avg. loss: 0.000101, [current:12800/32000]\n",
      "Avg. loss: 0.000067, [current:16000/32000]\n",
      "Avg. loss: 0.000077, [current:19200/32000]\n",
      "Avg. loss: 0.000042, [current:22400/32000]\n",
      "Avg. loss: 0.000161, [current:25600/32000]\n",
      "Avg. loss: 0.000077, [current:28800/32000]\n",
      "Avg. loss: 0.000071, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg. loss: 0.000122\n",
      "\n",
      "Epoch 20\n",
      "------------------------------\n",
      "Avg. loss: 0.000037, [current: 3200/32000]\n",
      "Avg. loss: 0.000352, [current: 6400/32000]\n",
      "Avg. loss: 0.000108, [current: 9600/32000]\n",
      "Avg. loss: 0.000381, [current:12800/32000]\n",
      "Avg. loss: 0.000115, [current:16000/32000]\n",
      "Avg. loss: 0.000084, [current:19200/32000]\n",
      "Avg. loss: 0.000121, [current:22400/32000]\n",
      "Avg. loss: 0.000061, [current:25600/32000]\n",
      "Avg. loss: 0.000070, [current:28800/32000]\n",
      "Avg. loss: 0.000189, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg. loss: 0.000092\n",
      "\n",
      "Epoch 21\n",
      "------------------------------\n",
      "Avg. loss: 0.000062, [current: 3200/32000]\n",
      "Avg. loss: 0.000199, [current: 6400/32000]\n",
      "Avg. loss: 0.000138, [current: 9600/32000]\n",
      "Avg. loss: 0.000123, [current:12800/32000]\n",
      "Avg. loss: 0.000047, [current:16000/32000]\n",
      "Avg. loss: 0.000047, [current:19200/32000]\n",
      "Avg. loss: 0.000044, [current:22400/32000]\n",
      "Avg. loss: 0.000043, [current:25600/32000]\n",
      "Avg. loss: 0.000051, [current:28800/32000]\n",
      "Avg. loss: 0.000050, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg. loss: 0.000114\n",
      "\n",
      "Epoch 22\n",
      "------------------------------\n",
      "Avg. loss: 0.000170, [current: 3200/32000]\n",
      "Avg. loss: 0.000031, [current: 6400/32000]\n",
      "Avg. loss: 0.000084, [current: 9600/32000]\n",
      "Avg. loss: 0.000074, [current:12800/32000]\n",
      "Avg. loss: 0.000113, [current:16000/32000]\n",
      "Avg. loss: 0.000048, [current:19200/32000]\n",
      "Avg. loss: 0.000026, [current:22400/32000]\n",
      "Avg. loss: 0.000027, [current:25600/32000]\n",
      "Avg. loss: 0.000119, [current:28800/32000]\n",
      "Avg. loss: 0.000039, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg. loss: 0.000068\n",
      "\n",
      "Epoch 23\n",
      "------------------------------\n",
      "Avg. loss: 0.000026, [current: 3200/32000]\n",
      "Avg. loss: 0.000286, [current: 6400/32000]\n",
      "Avg. loss: 0.000027, [current: 9600/32000]\n",
      "Avg. loss: 0.000054, [current:12800/32000]\n",
      "Avg. loss: 0.000045, [current:16000/32000]\n",
      "Avg. loss: 0.000039, [current:19200/32000]\n",
      "Avg. loss: 0.000054, [current:22400/32000]\n",
      "Avg. loss: 0.000045, [current:25600/32000]\n",
      "Avg. loss: 0.000064, [current:28800/32000]\n",
      "Avg. loss: 0.000030, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg. loss: 0.000163\n",
      "\n",
      "Epoch 24\n",
      "------------------------------\n",
      "Avg. loss: 0.000036, [current: 3200/32000]\n",
      "Avg. loss: 0.000029, [current: 6400/32000]\n",
      "Avg. loss: 0.000030, [current: 9600/32000]\n",
      "Avg. loss: 0.000037, [current:12800/32000]\n",
      "Avg. loss: 0.000032, [current:16000/32000]\n",
      "Avg. loss: 0.000031, [current:19200/32000]\n",
      "Avg. loss: 0.000039, [current:22400/32000]\n",
      "Avg. loss: 0.000128, [current:25600/32000]\n",
      "Avg. loss: 0.000054, [current:28800/32000]\n",
      "Avg. loss: 0.000047, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg. loss: 0.000128\n",
      "\n",
      "Epoch 25\n",
      "------------------------------\n",
      "Avg. loss: 0.000035, [current: 3200/32000]\n",
      "Avg. loss: 0.000058, [current: 6400/32000]\n",
      "Avg. loss: 0.000035, [current: 9600/32000]\n",
      "Avg. loss: 0.000018, [current:12800/32000]\n",
      "Avg. loss: 0.000045, [current:16000/32000]\n",
      "Avg. loss: 0.000028, [current:19200/32000]\n",
      "Avg. loss: 0.000029, [current:22400/32000]\n",
      "Avg. loss: 0.000030, [current:25600/32000]\n",
      "Avg. loss: 0.000043, [current:28800/32000]\n",
      "Avg. loss: 0.000036, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg. loss: 0.000065\n",
      "\n",
      "Epoch 26\n",
      "------------------------------\n",
      "Avg. loss: 0.000027, [current: 3200/32000]\n",
      "Avg. loss: 0.000123, [current: 6400/32000]\n",
      "Avg. loss: 0.000047, [current: 9600/32000]\n",
      "Avg. loss: 0.000074, [current:12800/32000]\n",
      "Avg. loss: 0.000070, [current:16000/32000]\n",
      "Avg. loss: 0.000020, [current:19200/32000]\n",
      "Avg. loss: 0.000058, [current:22400/32000]\n",
      "Avg. loss: 0.000029, [current:25600/32000]\n",
      "Avg. loss: 0.000058, [current:28800/32000]\n",
      "Avg. loss: 0.000044, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg. loss: 0.000073\n",
      "\n",
      "Epoch 27\n",
      "------------------------------\n",
      "Avg. loss: 0.000050, [current: 3200/32000]\n",
      "Avg. loss: 0.000015, [current: 6400/32000]\n",
      "Avg. loss: 0.000032, [current: 9600/32000]\n",
      "Avg. loss: 0.000096, [current:12800/32000]\n",
      "Avg. loss: 0.000095, [current:16000/32000]\n",
      "Avg. loss: 0.000026, [current:19200/32000]\n",
      "Avg. loss: 0.000081, [current:22400/32000]\n",
      "Avg. loss: 0.000043, [current:25600/32000]\n",
      "Avg. loss: 0.000451, [current:28800/32000]\n",
      "Avg. loss: 0.000019, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg. loss: 0.000071\n",
      "\n",
      "Epoch 28\n",
      "------------------------------\n",
      "Avg. loss: 0.000152, [current: 3200/32000]\n",
      "Avg. loss: 0.000023, [current: 6400/32000]\n",
      "Avg. loss: 0.000089, [current: 9600/32000]\n",
      "Avg. loss: 0.000022, [current:12800/32000]\n",
      "Avg. loss: 0.000048, [current:16000/32000]\n",
      "Avg. loss: 0.000074, [current:19200/32000]\n",
      "Avg. loss: 0.000030, [current:22400/32000]\n",
      "Avg. loss: 0.000032, [current:25600/32000]\n",
      "Avg. loss: 0.000028, [current:28800/32000]\n",
      "Avg. loss: 0.000033, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg. loss: 0.000078\n",
      "\n",
      "Epoch 29\n",
      "------------------------------\n",
      "Avg. loss: 0.000045, [current: 3200/32000]\n",
      "Avg. loss: 0.000024, [current: 6400/32000]\n",
      "Avg. loss: 0.000014, [current: 9600/32000]\n",
      "Avg. loss: 0.000043, [current:12800/32000]\n",
      "Avg. loss: 0.000057, [current:16000/32000]\n",
      "Avg. loss: 0.000017, [current:19200/32000]\n",
      "Avg. loss: 0.000052, [current:22400/32000]\n",
      "Avg. loss: 0.000112, [current:25600/32000]\n",
      "Avg. loss: 0.000010, [current:28800/32000]\n",
      "Avg. loss: 0.000113, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg. loss: 0.000135\n",
      "\n",
      "Epoch 30\n",
      "------------------------------\n",
      "Avg. loss: 0.000023, [current: 3200/32000]\n",
      "Avg. loss: 0.000030, [current: 6400/32000]\n",
      "Avg. loss: 0.000277, [current: 9600/32000]\n",
      "Avg. loss: 0.000015, [current:12800/32000]\n",
      "Avg. loss: 0.000172, [current:16000/32000]\n",
      "Avg. loss: 0.000175, [current:19200/32000]\n",
      "Avg. loss: 0.000025, [current:22400/32000]\n",
      "Avg. loss: 0.000092, [current:25600/32000]\n",
      "Avg. loss: 0.000045, [current:28800/32000]\n",
      "Avg. loss: 0.000058, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg. loss: 0.000030\n",
      "\n",
      "Epoch 31\n",
      "------------------------------\n",
      "Avg. loss: 0.000046, [current: 3200/32000]\n",
      "Avg. loss: 0.000011, [current: 6400/32000]\n",
      "Avg. loss: 0.000053, [current: 9600/32000]\n",
      "Avg. loss: 0.000019, [current:12800/32000]\n",
      "Avg. loss: 0.000023, [current:16000/32000]\n",
      "Avg. loss: 0.000032, [current:19200/32000]\n",
      "Avg. loss: 0.000011, [current:22400/32000]\n",
      "Avg. loss: 0.000016, [current:25600/32000]\n",
      "Avg. loss: 0.000044, [current:28800/32000]\n",
      "Avg. loss: 0.000015, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg. loss: 0.000043\n",
      "\n",
      "Epoch 32\n",
      "------------------------------\n",
      "Avg. loss: 0.000021, [current: 3200/32000]\n",
      "Avg. loss: 0.000098, [current: 6400/32000]\n",
      "Avg. loss: 0.000019, [current: 9600/32000]\n",
      "Avg. loss: 0.000024, [current:12800/32000]\n",
      "Avg. loss: 0.000033, [current:16000/32000]\n",
      "Avg. loss: 0.000188, [current:19200/32000]\n",
      "Avg. loss: 0.000024, [current:22400/32000]\n",
      "Avg. loss: 0.000073, [current:25600/32000]\n",
      "Avg. loss: 0.000019, [current:28800/32000]\n",
      "Avg. loss: 0.000018, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg. loss: 0.000148\n",
      "\n",
      "Epoch 33\n",
      "------------------------------\n",
      "Avg. loss: 0.000011, [current: 3200/32000]\n",
      "Avg. loss: 0.000099, [current: 6400/32000]\n",
      "Avg. loss: 0.000124, [current: 9600/32000]\n",
      "Avg. loss: 0.000010, [current:12800/32000]\n",
      "Avg. loss: 0.000033, [current:16000/32000]\n",
      "Avg. loss: 0.000015, [current:19200/32000]\n",
      "Avg. loss: 0.000021, [current:22400/32000]\n",
      "Avg. loss: 0.000057, [current:25600/32000]\n",
      "Avg. loss: 0.000023, [current:28800/32000]\n",
      "Avg. loss: 0.000054, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg. loss: 0.000032\n",
      "\n",
      "Epoch 34\n",
      "------------------------------\n",
      "Avg. loss: 0.000163, [current: 3200/32000]\n",
      "Avg. loss: 0.000019, [current: 6400/32000]\n",
      "Avg. loss: 0.000057, [current: 9600/32000]\n",
      "Avg. loss: 0.000010, [current:12800/32000]\n",
      "Avg. loss: 0.000021, [current:16000/32000]\n",
      "Avg. loss: 0.000010, [current:19200/32000]\n",
      "Avg. loss: 0.000068, [current:22400/32000]\n",
      "Avg. loss: 0.000032, [current:25600/32000]\n",
      "Avg. loss: 0.000021, [current:28800/32000]\n",
      "Avg. loss: 0.000031, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg. loss: 0.000050\n",
      "\n",
      "Epoch 35\n",
      "------------------------------\n",
      "Avg. loss: 0.000007, [current: 3200/32000]\n",
      "Avg. loss: 0.000030, [current: 6400/32000]\n",
      "Avg. loss: 0.000019, [current: 9600/32000]\n",
      "Avg. loss: 0.000022, [current:12800/32000]\n",
      "Avg. loss: 0.000025, [current:16000/32000]\n",
      "Avg. loss: 0.000091, [current:19200/32000]\n",
      "Avg. loss: 0.000017, [current:22400/32000]\n",
      "Avg. loss: 0.000019, [current:25600/32000]\n",
      "Avg. loss: 0.000012, [current:28800/32000]\n",
      "Avg. loss: 0.000036, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg. loss: 0.000089\n",
      "\n",
      "Epoch 36\n",
      "------------------------------\n",
      "Avg. loss: 0.000008, [current: 3200/32000]\n",
      "Avg. loss: 0.000011, [current: 6400/32000]\n",
      "Avg. loss: 0.000011, [current: 9600/32000]\n",
      "Avg. loss: 0.000483, [current:12800/32000]\n",
      "Avg. loss: 0.000055, [current:16000/32000]\n",
      "Avg. loss: 0.000021, [current:19200/32000]\n",
      "Avg. loss: 0.000021, [current:22400/32000]\n",
      "Avg. loss: 0.000010, [current:25600/32000]\n",
      "Avg. loss: 0.000009, [current:28800/32000]\n",
      "Avg. loss: 0.000025, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg. loss: 0.000026\n",
      "\n",
      "Epoch 37\n",
      "------------------------------\n",
      "Avg. loss: 0.000025, [current: 3200/32000]\n",
      "Avg. loss: 0.000020, [current: 6400/32000]\n",
      "Avg. loss: 0.000010, [current: 9600/32000]\n",
      "Avg. loss: 0.000017, [current:12800/32000]\n",
      "Avg. loss: 0.000008, [current:16000/32000]\n",
      "Avg. loss: 0.000426, [current:19200/32000]\n",
      "Avg. loss: 0.000013, [current:22400/32000]\n",
      "Avg. loss: 0.000019, [current:25600/32000]\n",
      "Avg. loss: 0.000011, [current:28800/32000]\n",
      "Avg. loss: 0.000017, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg. loss: 0.000040\n",
      "\n",
      "Epoch 38\n",
      "------------------------------\n",
      "Avg. loss: 0.000005, [current: 3200/32000]\n",
      "Avg. loss: 0.000050, [current: 6400/32000]\n",
      "Avg. loss: 0.000169, [current: 9600/32000]\n",
      "Avg. loss: 0.000005, [current:12800/32000]\n",
      "Avg. loss: 0.000052, [current:16000/32000]\n",
      "Avg. loss: 0.000031, [current:19200/32000]\n",
      "Avg. loss: 0.000031, [current:22400/32000]\n",
      "Avg. loss: 0.000006, [current:25600/32000]\n",
      "Avg. loss: 0.000010, [current:28800/32000]\n",
      "Avg. loss: 0.000043, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg. loss: 0.000062\n",
      "\n",
      "Epoch 39\n",
      "------------------------------\n",
      "Avg. loss: 0.000008, [current: 3200/32000]\n",
      "Avg. loss: 0.000075, [current: 6400/32000]\n",
      "Avg. loss: 0.000011, [current: 9600/32000]\n",
      "Avg. loss: 0.000007, [current:12800/32000]\n",
      "Avg. loss: 0.000027, [current:16000/32000]\n",
      "Avg. loss: 0.000009, [current:19200/32000]\n",
      "Avg. loss: 0.000019, [current:22400/32000]\n",
      "Avg. loss: 0.000013, [current:25600/32000]\n",
      "Avg. loss: 0.000015, [current:28800/32000]\n",
      "Avg. loss: 0.000005, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000026\n",
      "\n",
      "Epoch 40\n",
      "------------------------------\n",
      "Avg. loss: 0.000189, [current: 3200/32000]\n",
      "Avg. loss: 0.000216, [current: 6400/32000]\n",
      "Avg. loss: 0.000089, [current: 9600/32000]\n",
      "Avg. loss: 0.000006, [current:12800/32000]\n",
      "Avg. loss: 0.000018, [current:16000/32000]\n",
      "Avg. loss: 0.000075, [current:19200/32000]\n",
      "Avg. loss: 0.000005, [current:22400/32000]\n",
      "Avg. loss: 0.000025, [current:25600/32000]\n",
      "Avg. loss: 0.000014, [current:28800/32000]\n",
      "Avg. loss: 0.000016, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000028\n",
      "\n",
      "Epoch 41\n",
      "------------------------------\n",
      "Avg. loss: 0.000006, [current: 3200/32000]\n",
      "Avg. loss: 0.000043, [current: 6400/32000]\n",
      "Avg. loss: 0.000006, [current: 9600/32000]\n",
      "Avg. loss: 0.000029, [current:12800/32000]\n",
      "Avg. loss: 0.000025, [current:16000/32000]\n",
      "Avg. loss: 0.000008, [current:19200/32000]\n",
      "Avg. loss: 0.000021, [current:22400/32000]\n",
      "Avg. loss: 0.000020, [current:25600/32000]\n",
      "Avg. loss: 0.000081, [current:28800/32000]\n",
      "Avg. loss: 0.000012, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg. loss: 0.000045\n",
      "\n",
      "Epoch 42\n",
      "------------------------------\n",
      "Avg. loss: 0.000138, [current: 3200/32000]\n",
      "Avg. loss: 0.000009, [current: 6400/32000]\n",
      "Avg. loss: 0.000018, [current: 9600/32000]\n",
      "Avg. loss: 0.000022, [current:12800/32000]\n",
      "Avg. loss: 0.000036, [current:16000/32000]\n",
      "Avg. loss: 0.000022, [current:19200/32000]\n",
      "Avg. loss: 0.000032, [current:22400/32000]\n",
      "Avg. loss: 0.000025, [current:25600/32000]\n",
      "Avg. loss: 0.000008, [current:28800/32000]\n",
      "Avg. loss: 0.000048, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000024\n",
      "\n",
      "Epoch 43\n",
      "------------------------------\n",
      "Avg. loss: 0.000007, [current: 3200/32000]\n",
      "Avg. loss: 0.000021, [current: 6400/32000]\n",
      "Avg. loss: 0.000009, [current: 9600/32000]\n",
      "Avg. loss: 0.000016, [current:12800/32000]\n",
      "Avg. loss: 0.000004, [current:16000/32000]\n",
      "Avg. loss: 0.000008, [current:19200/32000]\n",
      "Avg. loss: 0.000014, [current:22400/32000]\n",
      "Avg. loss: 0.000012, [current:25600/32000]\n",
      "Avg. loss: 0.000007, [current:28800/32000]\n",
      "Avg. loss: 0.000015, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg. loss: 0.000110\n",
      "\n",
      "Epoch 44\n",
      "------------------------------\n",
      "Avg. loss: 0.000010, [current: 3200/32000]\n",
      "Avg. loss: 0.000023, [current: 6400/32000]\n",
      "Avg. loss: 0.000016, [current: 9600/32000]\n",
      "Avg. loss: 0.000030, [current:12800/32000]\n",
      "Avg. loss: 0.000006, [current:16000/32000]\n",
      "Avg. loss: 0.000016, [current:19200/32000]\n",
      "Avg. loss: 0.000006, [current:22400/32000]\n",
      "Avg. loss: 0.000017, [current:25600/32000]\n",
      "Avg. loss: 0.000006, [current:28800/32000]\n",
      "Avg. loss: 0.000014, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg. loss: 0.000030\n",
      "\n",
      "Epoch 45\n",
      "------------------------------\n",
      "Avg. loss: 0.000009, [current: 3200/32000]\n",
      "Avg. loss: 0.000014, [current: 6400/32000]\n",
      "Avg. loss: 0.000010, [current: 9600/32000]\n",
      "Avg. loss: 0.000023, [current:12800/32000]\n",
      "Avg. loss: 0.000018, [current:16000/32000]\n",
      "Avg. loss: 0.000004, [current:19200/32000]\n",
      "Avg. loss: 0.000017, [current:22400/32000]\n",
      "Avg. loss: 0.000005, [current:25600/32000]\n",
      "Avg. loss: 0.000003, [current:28800/32000]\n",
      "Avg. loss: 0.000036, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg. loss: 0.000036\n",
      "\n",
      "Epoch 46\n",
      "------------------------------\n",
      "Avg. loss: 0.000009, [current: 3200/32000]\n",
      "Avg. loss: 0.000014, [current: 6400/32000]\n",
      "Avg. loss: 0.000006, [current: 9600/32000]\n",
      "Avg. loss: 0.000021, [current:12800/32000]\n",
      "Avg. loss: 0.000003, [current:16000/32000]\n",
      "Avg. loss: 0.000008, [current:19200/32000]\n",
      "Avg. loss: 0.000011, [current:22400/32000]\n",
      "Avg. loss: 0.000015, [current:25600/32000]\n",
      "Avg. loss: 0.000016, [current:28800/32000]\n",
      "Avg. loss: 0.000013, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000036\n",
      "\n",
      "Epoch 47\n",
      "------------------------------\n",
      "Avg. loss: 0.000014, [current: 3200/32000]\n",
      "Avg. loss: 0.000040, [current: 6400/32000]\n",
      "Avg. loss: 0.000045, [current: 9600/32000]\n",
      "Avg. loss: 0.000006, [current:12800/32000]\n",
      "Avg. loss: 0.000036, [current:16000/32000]\n",
      "Avg. loss: 0.000026, [current:19200/32000]\n",
      "Avg. loss: 0.000007, [current:22400/32000]\n",
      "Avg. loss: 0.000065, [current:25600/32000]\n",
      "Avg. loss: 0.000007, [current:28800/32000]\n",
      "Avg. loss: 0.000006, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg. loss: 0.000019\n",
      "\n",
      "Epoch 48\n",
      "------------------------------\n",
      "Avg. loss: 0.000036, [current: 3200/32000]\n",
      "Avg. loss: 0.000024, [current: 6400/32000]\n",
      "Avg. loss: 0.000010, [current: 9600/32000]\n",
      "Avg. loss: 0.000009, [current:12800/32000]\n",
      "Avg. loss: 0.000009, [current:16000/32000]\n",
      "Avg. loss: 0.000013, [current:19200/32000]\n",
      "Avg. loss: 0.000006, [current:22400/32000]\n",
      "Avg. loss: 0.000012, [current:25600/32000]\n",
      "Avg. loss: 0.000013, [current:28800/32000]\n",
      "Avg. loss: 0.000035, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg. loss: 0.000024\n",
      "\n",
      "Epoch 49\n",
      "------------------------------\n",
      "Avg. loss: 0.000027, [current: 3200/32000]\n",
      "Avg. loss: 0.000074, [current: 6400/32000]\n",
      "Avg. loss: 0.000102, [current: 9600/32000]\n",
      "Avg. loss: 0.000008, [current:12800/32000]\n",
      "Avg. loss: 0.000004, [current:16000/32000]\n",
      "Avg. loss: 0.000019, [current:19200/32000]\n",
      "Avg. loss: 0.000013, [current:22400/32000]\n",
      "Avg. loss: 0.000096, [current:25600/32000]\n",
      "Avg. loss: 0.000005, [current:28800/32000]\n",
      "Avg. loss: 0.000018, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg. loss: 0.000011\n",
      "\n",
      "Epoch 50\n",
      "------------------------------\n",
      "Avg. loss: 0.000006, [current: 3200/32000]\n",
      "Avg. loss: 0.000003, [current: 6400/32000]\n",
      "Avg. loss: 0.000008, [current: 9600/32000]\n",
      "Avg. loss: 0.000004, [current:12800/32000]\n",
      "Avg. loss: 0.000033, [current:16000/32000]\n",
      "Avg. loss: 0.000003, [current:19200/32000]\n",
      "Avg. loss: 0.000009, [current:22400/32000]\n",
      "Avg. loss: 0.000057, [current:25600/32000]\n",
      "Avg. loss: 0.000005, [current:28800/32000]\n",
      "Avg. loss: 0.000005, [current:32000/32000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg. loss: 0.000015\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def epoch_loop(epochs, train_dataloader, test_dataloader, model, loss_fn, optimizer, tolerance, device=None, file_path=None):\n",
    "    if file_path:\n",
    "        ### BEGIN SOLUTION ###\n",
    "        epoch_last = restore_model_checkpoint(model, optimizer, train_dataloader, test_dataloader, file_path)\n",
    "        ### END SOLUTION ###\n",
    "    for t in range(epoch_last+1,epochs):\n",
    "        print(f\"Epoch {t+1}\\n------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(test_dataloader, model, loss_fn, tolerance, device)\n",
    "        if file_path:\n",
    "            ### BEGIN SOLUTION ###\n",
    "            save_model_checkpoint(model, optimizer, train_dataloader, t, file_path)\n",
    "            ### END SOLUTION ###\n",
    "    print(\"Done\")\n",
    "    return True\n",
    "\n",
    "use_model = NNModel(input_dims, output_dims, 20).to(device)\n",
    "use_optimizer = optim.SGD(use_model.parameters(), lr=learning_rate)\n",
    "my_epochs = 3\n",
    "assert epoch_loop(my_epochs, train_dataloader, test_dataloader, use_model, my_loss_fn, use_optimizer, tolerance, device, Path()/\"my_checkpoint_file.pth\")\n",
    "if torch.cuda.is_available():\n",
    "    my_epochs = epochs\n",
    "else:\n",
    "    my_epochs = 6\n",
    "assert epoch_loop(my_epochs, train_dataloader, test_dataloader, use_model, my_loss_fn, use_optimizer, tolerance, device, Path()/\"my_checkpoint_file.pth\")\n",
    "(Path()/\"my_checkpoint_file.pth\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891b993-e1e2-4b10-90cf-37841abe2585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
